{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing lyrics database\n",
    "\n",
    "### Database\n",
    "https://www.kaggle.com/datasets/jcecheverria/bad-bunny-lyrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U scikit-learn\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.manifold import TSNE\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     artists     album               title  title_with_featured  \\\n",
      "0  Bad Bunny  X 100pre      NI BIEN NI MAL       NI BIEN NI MAL   \n",
      "1  Bad Bunny  X 100pre             200 MPH  200 MPH (Ft. Diplo)   \n",
      "2  Bad Bunny  X 100pre     ¿Quién Tú Eres?      ¿Quién Tú Eres?   \n",
      "3  Bad Bunny  X 100pre                Caro                 Caro   \n",
      "4  Bad Bunny  X 100pre  Tenemos Que Hablar   Tenemos Que Hablar   \n",
      "\n",
      "                                              lyrics  \\\n",
      "0  [Letra de \"NI BIEN NI MAL\"]\\n\\n[Intro: Bad Bun...   \n",
      "1  [Letra de \"200 MPH\" ft. Diplo]\\n\\n[Intro]\\n¡Ju...   \n",
      "2  [Letra de \"¿Quién Tú Eres?\"]\\n\\n[Intro]\\nUh-uh...   \n",
      "3  [Letra de \"Caro\"]\\n\\n[Estribillo: Bad Bunny]\\n...   \n",
      "4  [Letra de \"Tenemos Que Hablar\"]\\n\\n[Intro]\\nYe...   \n",
      "\n",
      "                                                 url  \n",
      "0  https://genius.com/Bad-bunny-ni-bien-ni-mal-ly...  \n",
      "1        https://genius.com/Bad-bunny-200-mph-lyrics  \n",
      "2  https://genius.com/Bad-bunny-quien-tu-eres-lyrics  \n",
      "3           https://genius.com/Bad-bunny-caro-lyrics  \n",
      "4  https://genius.com/Bad-bunny-tenemos-que-habla...  \n"
     ]
    }
   ],
   "source": [
    "bb_db = pd.read_csv(\"../data/bad_bunny_lyrics.csv\")\n",
    "print(bb_db.head())\n",
    "lyrics_list = bb_db['lyrics']\n",
    "lyrics_es2coro = [l.replace(\"Estribillo\", \"Coro\") for l in lyrics_list]\n",
    "bb_db['lyrics'] = lyrics_es2coro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Letra de \"¿Quién Tú Eres?\"]\\n\\n[Intro]\\nUh-uh, uh-uh-uh-uh\\nRrrrr, ah-ah, ah-ah-ah-ah\\nRrrrr, uh-uh, uh-uh-uh-uh\\n¡Rrrrrrah!\\n\\n[Coro]\\n¿Quién tú eres? Ey\\nDime, socio, ¿quién tú ere\\'?\\nPa\\' frontearme a mí, ¿quién tú eres? Ey\\nHabla claro, ¿quién tú ere\\'? Ey\\nHuele bicho, ¿quién tú ere\\'? Ey\\nDime, socio, ¿quién tú ere\\'?\\nPa\\' frontearme a mí, ¿quién tú eres? Ey\\nHabla claro, ¿quién tú eres?\\nYeah, ven acá\\n\\n[Verso]\\n¿Cabrón, tú me pagas los biles? (¡No!)\\nTú hablando de mí y yo haciendo mile\\'\\nOtro palo pa\\' encima \\'e los files\\', ey\\nTú robando en Macy\\'s y yo en el desfile\\nHoy quiero una uruguaya y otra de Chile, ey, ey\\nOtro que me tira (¿Ah?)\\nCabrone\\', entiendan que pa\\' acá no se mira (¡No!)\\nYa mismo te cae, te tengo en la mira (Yeh; prr)\\nTú metío\\' en tu casa y yo de gira (Jaja)\\nVoy a las millas, como Toretto (¡Fum!)\\n¿Qué tú ere\\' el más duro? Te reto\\nYo tengo el imán, yo soy el Magneto, ey\\nA tu envidia en la cara le meto (Tss, tss-tss)\\nIván Calderón, pero a peso completo\\nEy, la familia en el Costal (Wuh)\\nUstede\\' son mis hijo\\' (Acucucu), pero los tuve que abortar\\nMe hice dueño del mundo y no lo quiero soltar\\nPor eso no me importa un carajo...\\n\\n[Coro]\\n¡Quién tú ere\\'! (Ey)\\nDime, socio, ¿quién tú ere\\'?\\nPa\\' frontearme a mí, ¿quién tú eres? Ey\\nHabla claro, ¿quién tú eres? Yeh-¡Ah!\\n¿Quién tú ere\\'?\\n\\n[Outro]\\nWho are you?\\nI know you know who I am\\nThe whole world knows who I am\\nBut who are you, nigga? Nobody\\nYou nobody, motherfucker\\nAsk around, nigga, ask around\\nThe whole world knows\\nEven you know, I\\'m the one\\nWho the fuck is you? Nobody\\nMotherfucker! Rrrah!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_db['lyrics'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_lyric_header(song_lyrics):\n",
    "    \"\"\"remove the header with artist and song name\"\"\"\n",
    "    start = 0\n",
    "    for ix, character in enumerate(list(song_lyrics)):\n",
    "        if character == \"]\":\n",
    "            start = ix\n",
    "            break\n",
    "    return song_lyrics[start+1:]\n",
    "\n",
    "def format_lyrics_string(l_string):\n",
    "    \"\"\" \"\"\"\n",
    "    # fmt_str = l_string.replace(\"\\n\", \" \").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    fmt_str = l_string.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    fmt_str = re.sub(r'(\\w)([.,?!;:])', r'\\1 \\2', fmt_str)\n",
    "    return fmt_str\n",
    "\n",
    "def get_section_starts(lyrics_nh):\n",
    "    \"\"\" \"\"\"\n",
    "    targets = [\"Coro\", \"Intro\", \"Verso\", \"Outro\"]\n",
    "    targets_index = {t: ix for ix, t in enumerate(targets)}\n",
    "    keys = ['intro',\n",
    "            'verse',\n",
    "            'chorus',\n",
    "            'outro']\n",
    "    \n",
    "    section_ix = []\n",
    "    section_type = []\n",
    "    \n",
    "    # find all section starts. store the starting index and categorize.\n",
    "    for ix, char in enumerate(list(lyrics_nh)):\n",
    "        if char == \"[\":\n",
    "            for t in targets:\n",
    "                if t in lyrics_nh[ix:ix+10]:\n",
    "                    for ix_end, char_end in enumerate(lyrics_nh[ix:]):\n",
    "                        if char_end == \"]\": \n",
    "                            section_ix.append((ix, ix+ix_end))\n",
    "                            section_type.append(t)\n",
    "                            break  \n",
    "    return section_type, section_ix\n",
    "    \n",
    "def make_body_ix(section_ix, lyrics_len):\n",
    "    \"\"\" \"\"\"\n",
    "    sections = []\n",
    "    for i, sec in enumerate(section_ix):\n",
    "        if sec == section_ix[-1]:\n",
    "            sections.append((sec[-1], lyrics_len))\n",
    "        else:\n",
    "            sections.append((sec[-1], section_ix[i+1][0]))    \n",
    "           \n",
    "    return sections\n",
    "    \n",
    "def make_lyrics_dict(lyrics, title):\n",
    "    \"\"\" \"\"\"\n",
    "    lyrics_dict = {key: [] for key in [\"Coro\", \"Intro\", \"Verso\", \"Outro\"]}\n",
    "    lyrics_len = len(lyrics)\n",
    "    section_type, section_ix = get_section_starts(lyrics)\n",
    "    sections = make_body_ix(section_ix, lyrics_len)\n",
    "    for t, sec in zip(*(section_type, sections)):\n",
    "        lyrics_dict[t].append(lyrics[sec[0]:sec[1]]) #add processing later\n",
    "    return lyrics_dict\n",
    "\n",
    "def remove_section_headers(lyrics):\n",
    "    \"\"\"\"\"\"\n",
    "    new_str_list = []\n",
    "    sw = 0\n",
    "    for i, ch  in enumerate(list(lyrics)):\n",
    "\n",
    "        if ch == \"[\":\n",
    "            sw = 1\n",
    "        elif ch == \"]\":\n",
    "            sw = 0\n",
    "        else:\n",
    "            if not sw:\n",
    "                new_str_list.append(ch)\n",
    "            else:\n",
    "                pass\n",
    "    return ''.join(new_str_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = bb_db['lyrics'][4]\n",
    "lyrics_len = len(lyrics)\n",
    "d = make_lyrics_dict(lyrics, 'TITLE')\n",
    "# print(get_section_starts(lyrics))\n",
    "# section_type, section_ix = get_section_starts(lyrics)\n",
    "# print(make_body_ix([(33, 39), (97, 102), (360, 368), (971, 976), (1371, 1379), (1647, 1652)], lyrics_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Odio tus mensajes , cuando dices Que tenemos que hablar Oh Dios , qué yo hice , qué yo hice  Que tenemos que hablar Odio tus mensajes , cuando dices Que tenemos que hablar Oh Dios , qué yo hice , qué yo hice  Que tenemos que hablar Yeah , yeah , yeah , yeah  '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = re.sub(r'(\\w)([.,?!;:])', r'\\1 \\2', d[\"Coro\"][0])\n",
    "s.replace(\"\\n\", \" \").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"¿\", \"\").replace(\"?\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '3', 'k', 's', 'k', 'j', 'f', 'j', 'l', 's']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(\"23kskjfjls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   Bla , bla , bla , bla , bla , bla Ey , yo, yo, yo Yo, yo, yo, yo, yah Lalalalalalala (Blow , blow) Lalalalalalala   Diablo , qué safaera Tú tiene un culo cabrón Cualquier cosa que te ponga rompe la carretera (Lalalalala ; aight) Muévelo , muévelo , muévelo , muévelo (Lalalalalalala) Qué safaera\\u205f(Lalalalala) Tiene\\u205fun\\u205fculo cabrón Cualquier cosa\\u205fque te ponga\\u205frompe la carretera (Aight ; tra !) Muévelo , muévelo , muévelo , muévelo   Qué falta de respeto , mami ¿Cómo te atreve a venir sin panty ? Hoy saliste puesta pa mí Yo que pensaba que venía a dormir , no Vino ready ya , puesta pa una cepillá Me chupa la lollipop , solita se arrodilla , hey ¿Cómo te atreve, mami , a venir sin panty ?   Mera , dímelo , DJ Orma ¿Qué tú te cree? Jodío cabrón , jeje Yo Hago Lo Que Me Da La Gana Díselo , Conejo Ey , ey (Jajajaja)   Hoy se bebe , hoy se gasta Hoy se fuma como un rasta Si Dio lo permite (Si Dio lo permite), ey Si Dio lo permite (Que si Dio lo permite), ey Hoy se bebe , hoy se gasta Hoy se fuma como un rasta (Woo , woo , woo) Si Dio lo permite (Jajajajaja), ey Si Dio lo permite (Yo, yo), ey   Real G , orientando la generacione nueva, con la verdadera Bellaqueo a lo galactic Sí , pa que se te mojen los panty Métele bellaco a lo versátil Má puta que Betty Boop La que se puso bellaca , mami , fuiste tú Sigo matando con la U Chocha con bicho , bicho con nalga (Empuja) Cho-Chocha con bicho , bicho con nalga , sí (Empuja) Chocha con bicho , bicho con nalga (Empuja) Te-Teta rozando mis tetilla (Empuja) Este año no quiero putilla (Empuja) Te ven con mucha prenda y te quieren pegar (Empuja) Te ven bien activao y te quieren pegar (Empuja) Porque está bien buena , porque está bien buena (Empújamelo completo) Teta bien grande como Lourdes Chacón Las nalga bien grande como Iris Chacón La chocha no sé porque no la he visto Pero vamo pa la cama a clavarte en panty   Hoy se bebe , hoy se gasta Hoy se fuma como un rasta Si Dio lo permite Si Dio lo permite , yeah-yeah Y hoy se bebe , hoy se gasta Hoy se fuma como un rasta Si Dio lo permite Si Dio lo permite (-te , -te , -te , -te , -te , -te)   (Arr-ugh !) Mami , ¿qué tú quiere? Aquí llegó tu tiburón Yo quiero perrearte y fumarme un blunt Ver lo que esconde ese pantalón Yo quiero perrearte y perrearte y perrearte (Duro , duro) Yo-Yo-Yo quiero perrearte y fumarme un blunt (Duro , duro) Yo quiero perrearte y perrearte y perrear (Duro , duro) Yo-Yo-Yo quiero perrearte y fumarme un blunt , -me un blunt (Duro , duro) La rola ya me explotó La nena bailando se botó Ese culo se merece to, se merece to, se merece to, yes Ese culo se merece to, se merece to, se merece to (Ey , ey , ey , ey , ey)   Ah ! Yo pensaba que se ponía lenta Tá bien , tá bien , vamo de nuevo , de nuevo Velen a Orma , velen a Orma que está bellaco Jajajaja (Jajajaja , jajajaja)   Mi bicho anda fugao y yo quiero que tú me lo esconda Agárralo como bonga Se mete una pepa que la pone cachonda Chinga en lo Audi , no en lo Honda , ey (Tra) Si te lo meto no me llame (Tra , tra) Que esto no e pa que me ame, ey (Tra , tra) Si tu novio no te mama el culo Pa eso que no mame   Baja pa casa que yo te lambo toa Mami , yo te lambo toa Baja pa casa que yo te rompo toa , ey Que yo te rompo toa Baja pa casa que yo te lambo toa (Papi , sigue !) Mami , yo te lambo toa (Papi , sigue !) Dime , sierva (Papi , sigue) Si tú fuma yerba (Papi , pa-papi)   Jowell , bebé , bebé , bebé , jaja , jajajajaja ! Perreando e la bichota (Duro !) Se ve que chinga rico en la nota Yo quiero tirarme un selfie con esa nalgota (Tra , tra ; wow) Parao , parao , parao lo tengo , se me nota (Woh , woh) ¿Qué vamo a hacer con esa nalgota? (What ?) En la uni toa son A , A , A (Tra) Pero esa teta son C Tú ere una superbellaca (Wuh), mami , yo lo sé (Eh) Yo también soy un bellaco (Tra), ¿qué vamo a hacer ? (Tú sabe, eh) Con ese bum-bum , guíllate , bum-bum Guíllate ese bum-bum , guíllate , bum-bum Si tiene ese bum-bum , guíllate , bum-bum Si tiene ese bum-bum , guíllate , buoh !'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_db['lyrics_no_headers'] = [format_lyrics_string(remove_section_headers(l)).replace('\\\\', '').replace(\"'\", \"\").replace(\"\\xa1\", \"\") for l in bb_db['lyrics']]\n",
    "bb_db['lyrics_no_headers'][36].replace(\"\\u2005\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'latin-1' codec can't encode character '\\u2014' in position 1302: ordinal not in range(256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bb_db\u001b[39m.\u001b[39;49mto_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/Users/jrd/Documents/DM2023/bb_db.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlatin-1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3773\u001b[0m     path_or_buf,\n\u001b[1;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[1;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3789\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/formats/csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/formats/csvs.py:264\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    263\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_header()\n\u001b[0;32m--> 264\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_body()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/formats/csvs.py:302\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m start_i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m end_i:\n\u001b[1;32m    301\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_chunk(start_i, end_i)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    310\u001b[0m data \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39miget_values(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(res\u001b[39m.\u001b[39mitems))]\n\u001b[1;32m    312\u001b[0m ix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_index[slicer]\u001b[39m.\u001b[39m_format_native_types(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_number_format)\n\u001b[0;32m--> 313\u001b[0m libwriters\u001b[39m.\u001b[39;49mwrite_csv_rows(\n\u001b[1;32m    314\u001b[0m     data,\n\u001b[1;32m    315\u001b[0m     ix,\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnlevels,\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcols,\n\u001b[1;32m    318\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwriter,\n\u001b[1;32m    319\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/_libs/writers.pyx:75\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'latin-1' codec can't encode character '\\u2014' in position 1302: ordinal not in range(256)"
     ]
    }
   ],
   "source": [
    "bb_db.to_csv(\"/Users/jrd/Documents/DM2023/bb_db.csv\", encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BloomForCausalLM\n",
    "from transformers import BloomTokenizerFast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "bigscience/bloom-1b3 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    262\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/bigscience/bloom-1b3/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    418\u001b[0m         path_or_repo_id,\n\u001b[1;32m    419\u001b[0m         filename,\n\u001b[1;32m    420\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    421\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    422\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    423\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    424\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    425\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    426\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    427\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    428\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    429\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    430\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1195\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     metadata \u001b[39m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1196\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1197\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1198\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1199\u001b[0m         timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m   1200\u001b[0m     )\n\u001b[1;32m   1201\u001b[0m \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m http_error:\n\u001b[1;32m   1202\u001b[0m     \u001b[39m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1541\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1532\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1533\u001b[0m     method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1534\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1539\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m   1540\u001b[0m )\n\u001b[0;32m-> 1541\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1543\u001b[0m \u001b[39m# Return\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:293\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[1;32m    286\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m make sure you are authenticated.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m     )\n\u001b[0;32m--> 293\u001b[0m     \u001b[39mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-64cd9be6-284b1309644b1fb054025ba9;a3c217b2-3b5a-4e34-b6b8-43bd2d1900f1)\n\nRepository Not Found for url: https://huggingface.co/bigscience/bloom-1b3/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m BloomForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mbigscience/bloom-1b3\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[39m=\u001b[39m BloomTokenizerFast\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mbigscience/bloom-1b3\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/modeling_utils.py:2325\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2324\u001b[0m     config_path \u001b[39m=\u001b[39m config \u001b[39mif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[0;32m-> 2325\u001b[0m     config, model_kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m   2326\u001b[0m         config_path,\n\u001b[1;32m   2327\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2328\u001b[0m         return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2329\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   2330\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   2331\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   2332\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   2333\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   2334\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2335\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   2336\u001b[0m         _from_auto\u001b[39m=\u001b[39;49mfrom_auto_class,\n\u001b[1;32m   2337\u001b[0m         _from_pipeline\u001b[39m=\u001b[39;49mfrom_pipeline,\n\u001b[1;32m   2338\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2339\u001b[0m     )\n\u001b[1;32m   2340\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2341\u001b[0m     model_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py:590\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mrevision\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m revision\n\u001b[1;32m    588\u001b[0m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_set_token_in_kwargs(kwargs, token)\n\u001b[0;32m--> 590\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type:\n\u001b[1;32m    592\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    593\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are using a model of type \u001b[39m\u001b[39m{\u001b[39;00mconfig_dict[\u001b[39m'\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m to instantiate a model of type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    594\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    595\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py:617\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    616\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 617\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    618\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[1;32m    619\u001b[0m     original_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/configuration_utils.py:672\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m configuration_file \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39m_configuration_file\u001b[39m\u001b[39m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    670\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    671\u001b[0m     \u001b[39m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 672\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    673\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    674\u001b[0m         configuration_file,\n\u001b[1;32m    675\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    676\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    677\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    678\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    679\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    680\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    681\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    682\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    683\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    684\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m     commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    687\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[39m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[39m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/utils/hub.py:433\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    417\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    418\u001b[0m         path_or_repo_id,\n\u001b[1;32m    419\u001b[0m         filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m         local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[1;32m    430\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m--> 433\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    434\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m     )\n\u001b[1;32m    439\u001b[0m \u001b[39mexcept\u001b[39;00m RevisionNotFoundError:\n\u001b[1;32m    440\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    441\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mrevision\u001b[39m}\u001b[39;00m\u001b[39m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfor this model name. Check the model page at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for available revisions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: bigscience/bloom-1b3 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "model = BloomForCausalLM.from_pretrained(\"bigscience/bloom-1b3\")\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloom-1b3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
